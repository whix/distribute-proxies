1.计划添加针对每个网站可用ip计数功能 2015-09-23 17:17:33


进度：
2015-09-24
    记录函数花费时间，方便优化：
        更新数据库能可用ip（update_db function), 耗时33min，大概500个ip。
            第二次数据：23min
            第三次数据：22min
        爬取相关网页上的ip地址（get_page_proxies function）, 耗时1min，大概200个网页
            第二次数据：1min
            第三次数据：<1min
        检查爬取的数据是否可用（filter_proxies function），timeout=5s，耗时6h10min，ip数量未知
            第二次数据：4h
            第三次数据：4h20min
    变更：取消之前更新三次数据库数据再执行一个ip爬取的机制，因为之前未考虑程序运行时间。基于提供ip的网站一般30分钟更新一次。现在一个爬取至少隔了4h。
    其他：今天同事工作分享，明天多花费半小时在这个程序上。

2015-09-25
    在Proxies 中添加了quantity 字段，默认为0，在filter_proxies 函数中，会把quantity 设为默认值0，在update_db 中会更新quantity 的值。
    下次进一步考虑是否需要创建一个新的表来管理。

2015-09-28
    出现错误，错误提示如下：
     Traceback (most recent call last):
       File "F:\\www\\distribute_proxies\\ManageProxies.py", line 121, in start_working_helper
         self.update_db()
       File "F:\\www\\distribute_proxies\\ManageProxies.py", line 53, in update_db
         proxies_list.quantity = Proxies.objects.filter(domain_name).count()
       File "C:\\Python27\\lib\\site-packages\\django\\db\\models\\manager.py", line 127, in manager_method
         return getattr(self.get_queryset(), name)(*args, **kwargs)
       File "C:\\Python27\\lib\\site-packages\\django\\db\\models\\query.py", line 679, in filter
         return self._filter_or_exclude(False, *args, **kwargs)
       File "C:\\Python27\\lib\\site-packages\\django\\db\\models\\query.py", line 697, in _filter_or_exclude
         clone.query.add_q(Q(*args, **kwargs))
       File "C:\\Python27\\lib\\site-packages\\django\\db\\models\\sql\\query.py", line 1301, in add_q
         clause, require_inner = self._add_q(where_part, self.used_aliases)
       File "C:\\Python27\\lib\\site-packages\\django\\db\\models\\sql\\query.py", line 1328, in _add_q
         current_negated=current_negated, connector=connector, allow_joins=allow_joins)
       File "C:\\Python27\\lib\\site-packages\\django\\db\\models\\sql\\query.py", line 1141, in build_filter
         arg, value = filter_expr
     ValueError: need more than 1 value to unpack
    调试解决ing...
    1.Entry.objects.filter(domain_name) 使用错误，直接查询关键字，改成使用Entry.objects.get(website__contains=domain_name)，看看是否有问题。
    2.改变了函数执行顺序，先更新数据库的ip，再去爬取。
    3.修改一个变量名错误。
    4.出现错误，忘记re.findall 返回的是一个list 了。

2015-09-29
    调试，目前数据显示正常。

2015-09-30
    添加一个新表？构思如何添加。

2015-10-09
    在Proxies 中添加一个外键，指向Domain，Domain 有domain 和quantity 字段。添加了相关程序进行测试。

2015-10-10
    Domain 的quantity 字段未更新。
    发现问题，赋值后没有save。
    目前工作正常，只是感觉在Pycharm 下执行程序比较慢。

2015-10-11
    移植到本机部署的项目上的时候出现了问题。主要是关于数据库迁移的问题，旧数据库已经存在Domain 表，更新失败，后来下载了一个Sqlite 管理器才把Domain 删除，然后migrate 成功。
    本来想在Domain 里添加一个datetime 字段，不知道为什么又不能添加，所以暂时就不添加了，先看看Domain 是否能正常存储信息。

2015-10-12
    Proxies 表中有很大一部分related_domain 字段都还是None ，而Domain 显示正常。

2015-10-13
    错误还未解决，有200多条记录未能统计。
    1、更新了一个错误，update_db 函数的缩进错误，类似于函数下的语句都缩进了2个Tab。
    2、把一个函数经历的时间显示为一行输出：print "update_db function between %s to %s" % (beg, datetime.now())
    3、去掉错误IP的输出，节省空间、速度，也方便查看log，之前的错误IP信息都没查看过。

2015-10-14
    进行优化，在验证IP的可用性时，IP可用需检查数据库是否已存在该IP直接用get_or_create()

2015-10-15
    进行优化，只要是耗时较长的update_db 和filter_proxies 两个部分

2015-10-16
    使用hawkrest 对API接口进行加密。使用过程中遇到的问题：
    1、之前用POST方法去测试一个ListView（只允许GET） ，后来才发现这个问题；
    2、使用hawkrequest --url 时，记得把url后面的'/'也加上，之前一直测试'http://127.0.0.1:8000/snippets'验证通不过，原来就是因为最后的'snippets/'的问题；
    3、hawkrest 的文档只介绍了用类模板视图的情况，试着找出如何在普通视图上运用hawk 验证。(勘误：APIView是要自己设定响应的)

2015-10-20
    修复了之前get_or_create的使用错误，defaults 写成了default，返回的是一个tuple，已经defaults 正确的使用方法。
    目前每次爬取到ip数量为5000-6000（5234,6030,5252）。耗时为6-7h。

2015-10-26
    更改了计数方式，现在在添加或删除之后更新数据，避免了计数的延时。
    计划为Domain 添加一个add_time字段，记录新增的域名添加的时间，

2015-11-03
    现在爬取到的待测试代理接近6000多个，进行验证需要7、8个小时，经过太长时间，可能有些代理已经失效了。
    目前用get_page_proxies 函数爬取到的待测试代理是存储在一个数组里的。
    发现可以把数组分成好几份，例如分成3份的话，处理一份只要2、3小时，就可以测试完一份代理后就更新下数据库的代理。
    这样可以提高数据库里代理的可用性。

2015-11-05
    添加对一次API链接处理的程序。对待验证代理进行分组处理。

2015-11-11
    并不需要对API链接进行特殊处理，因为每次调用就会返回一组新的代理IP。
    添加了之前已经挂掉了的'http://cn-proxy.com/' 网站。